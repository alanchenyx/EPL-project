{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data = []\n",
    "with open('./pos.txt','r',encoding = 'utf-8') as f:\n",
    "    for ele in f:\n",
    "        if \"\\\\\" in ele:\n",
    "            pass\n",
    "        else:\n",
    "            train_data.append(ele)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_target= []\n",
    "for i in range(len(train_data)):\n",
    "    train_target.append('pos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_neg= []\n",
    "with open('./neg.txt','r',encoding = 'utf-8') as f:\n",
    "    for ele in f:\n",
    "        if \"\\\\\" in ele:\n",
    "            pass\n",
    "        else:\n",
    "            train_neg.append(ele)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(len(train_neg)):\n",
    "    train_target.append('neg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_neu= []\n",
    "with open('./neu.txt','r',encoding = 'utf-8') as f:\n",
    "    for ele in f:\n",
    "        if \"\\\\\" in ele:\n",
    "            pass\n",
    "        else:\n",
    "            train_neu.append(ele)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(len(train_neu)):\n",
    "    train_target.append('neu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data = train_data+train_neg+train_neu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "combine = list(zip(train_data,train_target))\n",
    "random.shuffle(combine)\n",
    "new_train_data,new_train_target = zip(*combine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100335"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(new_train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_train_data = new_train_data[0:80000]\n",
    "final_train_target = new_train_target[0:80000]\n",
    "\n",
    "final_test_data = new_train_data[80001:100334]\n",
    "final_test_target = new_train_target[80001:100334]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.util import ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "snow_stemmer = SnowballStemmer(language='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def custom_tokenizer(text, use_stem=True, stemmer=snow_stemmer, use_pos=False, \n",
    "                     use_only_adj=False, use_bigrams=False, use_bigrams_only=False):\n",
    "    # Separate words\n",
    "    words = word_tokenize(text)\n",
    "    # PoS tagging words\n",
    "    if use_pos:\n",
    "        pos_tags = nltk.pos_tag(words)\n",
    "    else:\n",
    "        pos_tags = zip(words, [''] * len(words))\n",
    "    \n",
    "    tokens = []\n",
    "    # Special treatment for bigrams\n",
    "    if use_bigrams:\n",
    "        tokens += list(ngrams(words, n=2))\n",
    "        if use_bigrams_only:\n",
    "            return tokens\n",
    "        else:\n",
    "            tokens += [(x,) for x in words]\n",
    "        return tokens\n",
    "    \n",
    "    for word, tag in pos_tags:\n",
    "        res_word = word\n",
    "        use_word = True\n",
    "        # Convert to stem\n",
    "        if use_stem:\n",
    "            res_word = stemmer.stem(res_word)\n",
    "        # Use POS tag with the word\n",
    "        if use_pos and not use_only_adj:\n",
    "            res_word += '_' + tag\n",
    "        # Only use adv and adj\n",
    "        if use_only_adj and not (tag[:2] == 'JJ' or tag[:2] == 'RB'):\n",
    "            use_word = False\n",
    "        # Append the word to the tokenizer\n",
    "        if use_word:\n",
    "            tokens.append(res_word)\n",
    "    return tokens\n",
    "\n",
    "def text_stems_tok(text):\n",
    "    return custom_tokenizerC\n",
    "def pos_tok(text):\n",
    "    return custom_tokenizer(text, use_stem=False, use_pos=True)\n",
    "def pos_stems_tok(text):\n",
    "    return custom_tokenizer(text, use_stem=True, use_pos=True)\n",
    "def adj_tok(text):\n",
    "    return custom_tokenizer(text, use_stem=False, use_pos=True, use_only_adj=True)\n",
    "def adj_stems_tok(text):\n",
    "    return custom_tokenizer(text, use_stem=True, use_pos=True, use_only_adj=True)\n",
    "def unigrams(text):\n",
    "    return word_tokenize(text)\n",
    "def uni_bigrams(text):\n",
    "    return custom_tokenizer(text, use_bigrams=True)\n",
    "def bigrams(text):\n",
    "    return custom_tokenizer(text, use_bigrams=True, use_bigrams_only=True)\n",
    "def uni_bigrams_stems(text):\n",
    "    tokens = uni_bigrams(text)\n",
    "    res_tokens = []\n",
    "    for t in tokens:\n",
    "        res_tokens.append(tuple([snow_stemmer.stem(x) for x in t]))\n",
    "    return res_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80000, 42581)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vect = CountVectorizer(tokenizer=unigrams)\n",
    "X_train_counts = count_vect.fit_transform(final_train_data)\n",
    "X_train_counts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<80000x42581 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 628867 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80000, 42581)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "tf_transformer = TfidfTransformer(use_idf=True).fit(X_train_counts)\n",
    "X_train_tf = tf_transformer.transform(X_train_counts)\n",
    "X_train_tf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
       "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
       "       learning_rate='optimal', loss='hinge', n_iter=5, n_jobs=1,\n",
       "       penalty='l2', power_t=0.5, random_state=None, shuffle=True,\n",
       "       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "text_clf = SGDClassifier()\n",
    "text_clf.fit(X_train_tf, final_train_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:14: DeprecationWarning: generator 'ngrams' raised StopIteration\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "svc_model = svm.SVC(gamma=0.001, C=100., kernel='linear')\n",
    "svc_clf = Pipeline([('vect', CountVectorizer(tokenizer=uni_bigrams_stems)),\n",
    "                     ('tfidf', TfidfTransformer(use_idf=True)),\n",
    "                     ('clf', svc_model)\n",
    "                    ])\n",
    "\n",
    "svc_clf = svc_clf.fit(final_train_data, final_train_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:14: DeprecationWarning: generator 'ngrams' raised StopIteration\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9110805095165494"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "predicted = svc_clf.predict(final_test_data)\n",
    "np.mean(predicted == final_test_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:14: DeprecationWarning: generator 'ngrams' raised StopIteration\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "svc_model = svm.SVC(gamma=0.001, C=100., kernel='rbf')\n",
    "svc_clf = Pipeline([('vect', CountVectorizer(tokenizer=uni_bigrams_stems)),\n",
    "                     ('tfidf', TfidfTransformer(use_idf=True)),\n",
    "                     ('clf', svc_model)\n",
    "                    ])\n",
    "\n",
    "svc_clf = svc_clf.fit(final_train_data, final_train_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:14: DeprecationWarning: generator 'ngrams' raised StopIteration\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.88250627059459996"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "predicted = svc_clf.predict(final_test_data)\n",
    "np.mean(predicted == final_test_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:14: DeprecationWarning: generator 'ngrams' raised StopIteration\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "svc_model = svm.SVC(gamma=0.001, C=100., kernel='sigmoid')\n",
    "svc_clf = Pipeline([('vect', CountVectorizer(tokenizer=uni_bigrams_stems)),\n",
    "                     ('tfidf', TfidfTransformer(use_idf=True)),\n",
    "                     ('clf', svc_model)\n",
    "                    ])\n",
    "\n",
    "svc_clf = svc_clf.fit(final_train_data, final_train_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:14: DeprecationWarning: generator 'ngrams' raised StopIteration\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.86111247725372542"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "predicted = svc_clf.predict(final_test_data)\n",
    "np.mean(predicted == final_test_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sklearn pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "text_clf = Pipeline([('vect', CountVectorizer(tokenizer=uni_bigrams_stems)),\n",
    "                     ('tfidf', TfidfTransformer(use_idf=True)),\n",
    "                     ('clf', SGDClassifier())\n",
    "                    ])\n",
    "                     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:14: DeprecationWarning: generator 'ngrams' raised StopIteration\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "text_clf = text_clf.fit(final_train_data, final_train_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:14: DeprecationWarning: generator 'ngrams' raised StopIteration\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.86691585107952585"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "predicted = text_clf.predict(final_test_data)\n",
    "np.mean(predicted == final_test_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['svm.pkl']"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#export the model\n",
    "from sklearn.externals import joblib\n",
    "joblib.dump(text_clf, 'svm.pkl', compress=9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "new_text_pipe = Pipeline([\n",
    "    ('bow', CountVectorizer(ngram_range=(1,2), min_df=2)),\n",
    "    #('tf-idf', TfidfTransformer()),\n",
    "    ('lr', LogisticRegression())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr_clf = new_text_pipe.fit(final_train_data, final_train_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.91265430580829199"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "predicted = lr_clf.predict(final_test_data)\n",
    "np.mean(predicted == final_test_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['logistic.pkl']"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#export the model\n",
    "from sklearn.externals import joblib\n",
    "joblib.dump(lr_clf, 'logistic.pkl', compress=9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "mlp = Pipeline([\n",
    "    ('bow', CountVectorizer(ngram_range=(1,2), min_df=2)),\n",
    "    #('tf-idf', TfidfTransformer()),\n",
    "    ('mlp', MLPClassifier())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mlp_ANN = mlp.fit(final_train_data, final_train_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.75996857198978585"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "predicted = mlp_ANN.predict(final_test_data)\n",
    "np.mean(predicted == final_test_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = Pipeline([\n",
    "    ('bow', CountVectorizer(ngram_range=(1,2), min_df=2)),\n",
    "    #('tf-idf', TfidfTransformer()),\n",
    "    ('knn', KNeighborsClassifier())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "knn_clf = knn.fit(final_train_data, final_train_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.84325972556927165"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "predicted = knn_clf.predict(final_test_data)\n",
    "np.mean(predicted == final_test_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['KNN.pkl']"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#export the model\n",
    "from sklearn.externals import joblib\n",
    "joblib.dump(knn_clf, 'KNN.pkl', compress=9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "NB = Pipeline([\n",
    "    ('bow', CountVectorizer(ngram_range=(1,2), min_df=2)),\n",
    "    #('tf-idf', TfidfTransformer()),\n",
    "    ('NB', MultinomialNB())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nb = NB.fit(final_train_data, final_train_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.80632488705558825"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "predicted = nb.predict(final_test_data)\n",
    "np.mean(predicted == final_test_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AdaBoostTree Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "adaboost = Pipeline([\n",
    "    ('bow', CountVectorizer(ngram_range=(1,2), min_df=2)),\n",
    "    #('tf-idf', TfidfTransformer()),\n",
    "    ('adaboost', AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=50),n_estimators=120, learning_rate=0.1))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ad = adaboost.fit(final_train_data, final_train_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.78570025535258303"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "predicted = ad.predict(final_test_data)\n",
    "np.mean(predicted == final_test_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
